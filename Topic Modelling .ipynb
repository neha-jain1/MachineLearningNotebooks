{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9604ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81fbcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document Category\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Document': corpus, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301f8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower(text):\n",
    "    text = text.lower()\n",
    "    return text \n",
    "\n",
    "def expand_contractions(text):\n",
    "    text = contractions.fix(text)\n",
    "    return text \n",
    "\n",
    "def remove_special_character(text):\n",
    "    text = text.replace('...',' ')\n",
    "    text = re.sub('[^a-zA-Z\\s]','',text)\n",
    "    return text\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(w) for w in text.split(' ')]\n",
    "    return ' '.join(text)\n",
    "\n",
    "def stopword_removal(text):\n",
    "    text = [w for w in text.split(' ') if w not in stop_words]\n",
    "    return ' '.join(text)\n",
    "\n",
    "def special_mention(text):\n",
    "    text = re.sub('@\\w+','',text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9708eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = convert_lower(text)\n",
    "\n",
    "    text = expand_contractions(text)\n",
    "\n",
    "   # text = special_mention(text)\n",
    "\n",
    "    text = remove_special_character(text)\n",
    "\n",
    "    text = stemming(text)\n",
    "\n",
    "    text = stopword_removal(text)\n",
    "    \n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e34d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df['clean_text'] = corpus_df['Document'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99a2d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>sky blue beauti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>love thi blue beauti sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>quick brown fox jump lazi dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>king breakfast ha sausag ham bacon egg toast bean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>love green egg ham sausag bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>brown fox quick blue dog lazi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>sky veri blue sky veri beauti today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>dog lazi brown fox quick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "  Category                                         clean_text  \n",
       "0  weather                                    sky blue beauti  \n",
       "1  weather                           love thi blue beauti sky  \n",
       "2  animals                      quick brown fox jump lazi dog  \n",
       "3     food  king breakfast ha sausag ham bacon egg toast bean  \n",
       "4     food                    love green egg ham sausag bacon  \n",
       "5  animals                      brown fox quick blue dog lazi  \n",
       "6  weather                sky veri blue sky veri beauti today  \n",
       "7  animals                           dog lazi brown fox quick  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32354b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca56184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sky blue beauti',\n",
       " 'love thi blue beauti sky',\n",
       " 'quick brown fox jump lazi dog',\n",
       " 'king breakfast ha sausag ham bacon egg toast bean',\n",
       " 'love green egg ham sausag bacon',\n",
       " 'brown fox quick blue dog lazi',\n",
       " 'sky veri blue sky veri beauti today',\n",
       " 'dog lazi brown fox quick']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = list(corpus_df['clean_text'].values)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06127a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''\n",
    "for s in doc:\n",
    "    corpus = corpus + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64946cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sky blue beautilove thi blue beauti skyquick brown fox jump lazi dogking breakfast ha sausag ham bacon egg toast beanlove green egg ham sausag baconbrown fox quick blue dog lazisky veri blue sky veri beauti todaydog lazi brown fox quick'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94895028",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f659e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf866c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb9f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cnt.fit_transform(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90f25f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x23 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67678353",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(data.toarray(),columns=sorted(cnt.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5953971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb890df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sky blue beauti',\n",
       " 'love thi blue beauti sky',\n",
       " 'quick brown fox jump lazi dog',\n",
       " 'king breakfast ha sausag ham bacon egg toast bean',\n",
       " 'love green egg ham sausag bacon',\n",
       " 'brown fox quick blue dog lazi',\n",
       " 'sky veri blue sky veri beauti today',\n",
       " 'dog lazi brown fox quick']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "236877d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon</th>\n",
       "      <th>bean</th>\n",
       "      <th>beauti</th>\n",
       "      <th>blue</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>egg</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>...</th>\n",
       "      <th>king</th>\n",
       "      <th>lazi</th>\n",
       "      <th>love</th>\n",
       "      <th>quick</th>\n",
       "      <th>sausag</th>\n",
       "      <th>sky</th>\n",
       "      <th>thi</th>\n",
       "      <th>toast</th>\n",
       "      <th>today</th>\n",
       "      <th>veri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon  bean  beauti  blue  breakfast  brown  dog  egg  fox  green  ...  \\\n",
       "0      0     0       1     1          0      0    0    0    0      0  ...   \n",
       "1      0     0       1     1          0      0    0    0    0      0  ...   \n",
       "2      0     0       0     0          0      1    1    0    1      0  ...   \n",
       "3      1     1       0     0          1      0    0    1    0      0  ...   \n",
       "4      1     0       0     0          0      0    0    1    0      1  ...   \n",
       "5      0     0       0     1          0      1    1    0    1      0  ...   \n",
       "6      0     0       1     1          0      0    0    0    0      0  ...   \n",
       "7      0     0       0     0          0      1    1    0    1      0  ...   \n",
       "\n",
       "   king  lazi  love  quick  sausag  sky  thi  toast  today  veri  \n",
       "0     0     0     0      0       0    1    0      0      0     0  \n",
       "1     0     0     1      0       0    1    1      0      0     0  \n",
       "2     0     1     0      1       0    0    0      0      0     0  \n",
       "3     1     0     0      0       1    0    0      1      0     0  \n",
       "4     0     0     1      0       1    0    0      0      0     0  \n",
       "5     0     1     0      1       0    0    0      0      0     0  \n",
       "6     0     0     0      0       0    2    0      0      1     2  \n",
       "7     0     1     0      1       0    0    0      0      0     0  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56981181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sky', 'blue', 'beauti', 'love', 'thi', 'quick', 'brown', 'fox', 'jump', 'lazi', 'dog', 'king', 'breakfast', 'ha', 'sausag', 'ham', 'bacon', 'egg', 'toast', 'bean', 'green', 'veri', 'today'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466d7b7",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a11d9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8322dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef8aa39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ = [d.split(' ') for d in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3d353bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = corpora.Dictionary(doc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afd5c7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x2070c21b520>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1f7c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dic.doc2bow(d) for d in doc_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22487868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)],\n",
       " [(11, 1),\n",
       "  (12, 1),\n",
       "  (13, 1),\n",
       "  (14, 1),\n",
       "  (15, 1),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1)],\n",
       " [(3, 1), (11, 1), (14, 1), (16, 1), (18, 1), (20, 1)],\n",
       " [(1, 1), (5, 1), (6, 1), (7, 1), (9, 1), (10, 1)],\n",
       " [(0, 1), (1, 1), (2, 2), (21, 1), (22, 2)],\n",
       " [(5, 1), (6, 1), (7, 1), (9, 1), (10, 1)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "341861de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sky', 'blue', 'beauti'],\n",
       " ['love', 'thi', 'blue', 'beauti', 'sky'],\n",
       " ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog'],\n",
       " ['king', 'breakfast', 'ha', 'sausag', 'ham', 'bacon', 'egg', 'toast', 'bean'],\n",
       " ['love', 'green', 'egg', 'ham', 'sausag', 'bacon'],\n",
       " ['brown', 'fox', 'quick', 'blue', 'dog', 'lazi'],\n",
       " ['sky', 'veri', 'blue', 'sky', 'veri', 'beauti', 'today'],\n",
       " ['dog', 'lazi', 'brown', 'fox', 'quick']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dedde965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4553e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ab16655",
   "metadata": {},
   "outputs": [],
   "source": [
    "termsMatrix = lda(doc_term_matrix,num_topics=3, id2word=dic,passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e46e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.098*\"love\" + 0.098*\"ham\" + 0.098*\"bacon\" + 0.098*\"sausag\" + 0.098*\"egg\"'),\n",
       " (1,\n",
       "  '0.105*\"brown\" + 0.105*\"quick\" + 0.105*\"fox\" + 0.105*\"lazi\" + 0.105*\"dog\"'),\n",
       " (2,\n",
       "  '0.096*\"beauti\" + 0.095*\"sky\" + 0.095*\"blue\" + 0.054*\"bean\" + 0.054*\"breakfast\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termsMatrix.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7e3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de937979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.084*\"sky\" + 0.078*\"blue\" + 0.067*\"beauti\"'),\n",
       " (1, '0.086*\"lazi\" + 0.086*\"quick\" + 0.077*\"brown\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "termsMatrix.print_topics(num_words=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30515296",
   "metadata": {},
   "source": [
    "### POS Tagging - Useful / Implied in Language Translation Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db5f3817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17811074",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4950d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Google is used by language translations and is an application of NLP .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8621369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Sundar Pichai is the CEO of Google. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9bab959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sundar --->  PROPN  ---->  NNP\n",
      "Pichai --->  PROPN  ---->  NNP\n",
      "is --->  AUX  ---->  VBZ\n",
      "the --->  DET  ---->  DT\n",
      "CEO --->  NOUN  ---->  NN\n",
      "of --->  ADP  ---->  IN\n",
      "Google --->  PROPN  ---->  NNP\n",
      ". --->  PUNCT  ---->  .\n"
     ]
    }
   ],
   "source": [
    "for t in nlp(s):\n",
    "    print(t.text, '---> ',  t.pos_, ' ----> ', t.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84402bc",
   "metadata": {},
   "source": [
    "## NER Named Entity Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "346ca99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fc08859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag.stanford import StanfordNERTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7463387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/software/stanford-corenlp-latest.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59b891bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = './stanford-corenlp-4.5.4-models-english/edu/stanford/nlp/models/ner/english.all.3class.caseless.distsim.crf.ser.gz'\n",
    "jar='./stanford-corenlp-4.5.4-models-english.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cf85e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\n  NLTK was unable to find stanford-ner.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-ner.jar, see:\n    <https://nlp.stanford.edu/software>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tagger \u001b[38;5;241m=\u001b[39m \u001b[43mStanfordNERTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish.all.3class.distsim.crf.ser.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py:200\u001b[0m, in \u001b[0;36mStanfordNERTagger.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py:70\u001b[0m, in \u001b[0;36mStanfordTagger.__init__\u001b[1;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_JAR:\n\u001b[0;32m     65\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe StanfordTagger class is not meant to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstantiated directly. Did you mean \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStanfordPOSTagger or StanfordNERTagger?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stanford_jar \u001b[38;5;241m=\u001b[39m \u001b[43mfind_jar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_JAR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_jar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearchpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stanford_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stanford_model \u001b[38;5;241m=\u001b[39m find_file(\n\u001b[0;32m     75\u001b[0m     model_filename, env_vars\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTANFORD_MODELS\u001b[39m\u001b[38;5;124m\"\u001b[39m,), verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoding \u001b[38;5;241m=\u001b[39m encoding\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py:848\u001b[0m, in \u001b[0;36mfind_jar\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_jar\u001b[39m(\n\u001b[0;32m    840\u001b[0m     name_pattern,\n\u001b[0;32m    841\u001b[0m     path_to_jar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    846\u001b[0m     is_regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    847\u001b[0m ):\n\u001b[1;32m--> 848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfind_jar_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_jar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearchpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_regex\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\internals.py:836\u001b[0m, in \u001b[0;36mfind_jar_iter\u001b[1;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[0;32m    831\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  For more information, on \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    <\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    832\u001b[0m         name_pattern,\n\u001b[0;32m    833\u001b[0m         url,\n\u001b[0;32m    834\u001b[0m     )\n\u001b[0;32m    835\u001b[0m div \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m75\u001b[39m\n\u001b[1;32m--> 836\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdiv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\n  NLTK was unable to find stanford-ner.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-ner.jar, see:\n    <https://nlp.stanford.edu/software>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "tagger = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c7aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
